{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26ad060e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T00:35:24.926376Z",
     "start_time": "2022-09-13T00:35:24.923877Z"
    }
   },
   "source": [
    "# RomyEvents - Automatic Eventplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa47ca0c",
   "metadata": {},
   "source": [
    "Creates automatic event plots based on catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae027cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:44:23.247899Z",
     "start_time": "2023-07-28T13:44:20.435586Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import obspy as obs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from obspy.geodetics import gps2dist_azimuth\n",
    "from pprint import pprint\n",
    "from functions.add_distances_and_backazimuth import __add_distances_and_backazimuth\n",
    "from functions.querrySeismoData import __querrySeismoData\n",
    "from obspy import read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d6b6c9",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba781332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:44:23.282869Z",
     "start_time": "2023-07-28T13:44:23.269015Z"
    },
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __makeplot(config, st):\n",
    "\n",
    "\n",
    "    st_in = st.copy()\n",
    "\n",
    "    fig, ax = plt.subplots(11,1, figsize=(15,20), sharex=True)    #eig fig, ax = plt.subplots(6,1, figsize=(15,10), sharex=True)\n",
    "\n",
    "    font = 14\n",
    "\n",
    "    time_scaling, time_unit = 1, \"sec\"\n",
    "    #Möglichkeit für bestimmte Einheit\n",
    "    #rot_scaling = 1    #urspr. 1e9\n",
    "    #trans_scaling = 1    #urspr. 1e6\n",
    "\n",
    "    for i, tr in enumerate(st_in):\n",
    "\n",
    "        if i in [0,1,2]:\n",
    "            #ax[i].set_ylabel(r\"$\\omega$ (nrad/s)\", fontsize=font)\n",
    "            ax[i].plot(tr.times()/time_scaling, tr.data, 'k', label=tr.stats.station+\".\"+tr.stats.channel)\n",
    "\n",
    "        elif i in [3,4,5,6,7,8,9,10,11]:\n",
    "            #ax[i].set_ylabel(r\"u ($\\mu$m/s)\", fontsize=font)\n",
    "            ax[i].plot(tr.times()/time_scaling, tr.data, 'k', label=tr.stats.station+\".\"+tr.stats.channel)\n",
    "\n",
    "        ax[i].legend(loc=1)\n",
    "\n",
    "    ax[10].set_xlabel(f\"Time ({time_unit}) from {st[0].stats.starttime.date} {str(st[0].stats.starttime.time).split('.')[0]} UTC\", fontsize=font)\n",
    "    ax[0].set_title(config['title']+f\" | {config['fmin']} - {config['fmax']} Hz\", fontsize=font, pad=10)\n",
    "\n",
    "    plt.show();\n",
    "    del st_in\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b96a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:44:23.299423Z",
     "start_time": "2023-07-28T13:44:23.283746Z"
    },
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __makeplotStreamSpectra2(st, config, fscale=None):\n",
    "\n",
    "    from scipy import fftpack\n",
    "    from andbro__fft import __fft\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    st_in = st.copy()\n",
    "\n",
    "    NN = len(st_in)\n",
    "    rot_scaling, rot_unit = 1e9, r\"nrad/s\"\n",
    "    trans_scaling, trans_unit = 1e6, r\"$\\mu$m/s\"\n",
    "\n",
    "    fig, axes = plt.subplots(NN,2,figsize=(15,int(NN*2)), sharex='col')\n",
    "\n",
    "    font = 14\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "    ## _______________________________________________\n",
    "\n",
    "    st.sort(keys=['channel'], reverse=True)\n",
    "\n",
    "    for i, tr in enumerate(st_in):\n",
    "\n",
    "#         comp_fft = abs(fftpack.fft(tr.data))\n",
    "#         ff       = fftpack.fftfreq(comp_fft.size, d=1/tr.stats.sampling_rate)\n",
    "#         comp_fft = fftpack.fftshift(comp_fft)\n",
    "#         ff, spec = ff[1:len(ff)//2], abs(fftpack.fft(tr.data)[1:len(ff)//2])\n",
    "\n",
    "        if tr.stats.channel[-2] == \"J\":\n",
    "            scaling = rot_scaling\n",
    "        elif tr.stats.channel[-2] == \"H\":\n",
    "            scaling = trans_scaling\n",
    "\n",
    "        spec, ff, ph = __fft(tr.data*scaling, tr.stats.delta, window=None, normalize=None)\n",
    "\n",
    "\n",
    "        ## _________________________________________________________________\n",
    "        if tr.stats.channel[-2] == \"J\":\n",
    "            axes[i,0].plot(\n",
    "                        tr.times(),\n",
    "                        tr.data*rot_scaling,\n",
    "                        color='black',\n",
    "                        label='{} {}'.format(tr.stats.station, tr.stats.channel),\n",
    "                        lw=1.0,\n",
    "                        )\n",
    "\n",
    "        elif tr.stats.channel[-2] == \"H\":\n",
    "            axes[i,0].plot(\n",
    "                        tr.times(),\n",
    "                        tr.data*trans_scaling,\n",
    "                        color='black',\n",
    "                        label='{} {}'.format(tr.stats.station, tr.stats.channel),\n",
    "                        lw=1.0,\n",
    "                        )\n",
    "        ## _________________________________________________________________\n",
    "        if fscale == \"loglog\":\n",
    "            axes[i,1].loglog(ff, spec, color='black', lw=1.0)\n",
    "        elif fscale == \"loglin\":\n",
    "            axes[i,1].semilogx(ff, spec, color='black', lw=1.0)\n",
    "        elif fscale == \"linlog\":\n",
    "            axes[i,1].semilogy(ff, spec, color='black', lw=1.0)\n",
    "        else:\n",
    "            axes[i,1].plot(ff, spec, color='black', lw=1.0)         \n",
    "\n",
    "\n",
    "        if tr.stats.channel[1] == \"J\":\n",
    "            sym, unit = r\"$\\Omega$\", rot_unit\n",
    "        elif tr.stats.channel[1] == \"H\":\n",
    "            sym, unit = \"v\", trans_unit\n",
    "        else:\n",
    "            unit = \"Amplitude\", \"a.u.\"\n",
    "\n",
    "        axes[i,0].set_ylabel(f'{sym} ({unit})',fontsize=font)    \n",
    "        axes[i,1].set_ylabel(f'ASD \\n({unit}/Hz)',fontsize=font)        \n",
    "        axes[i,0].legend(loc='upper left',bbox_to_anchor=(0.8, 1.10), framealpha=1.0)\n",
    "\n",
    "#         axes[i,0].ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "#         axes[i,1].ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "\n",
    "    if \"fmin\" in config.keys() and \"fmax\" in config.keys():\n",
    "        axes[i,1].set_xlim(config['fmin'],config['fmax'])\n",
    "\n",
    "    axes[NN-1,0].set_xlabel(f\"Time from {tr.stats.starttime.date} {str(tr.stats.starttime.time)[:8]} (s)\",fontsize=font)     \n",
    "    axes[NN-1,1].set_xlabel(f\"Frequency (Hz)\",fontsize=font)     \n",
    "\n",
    "    del st_in\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cfd05f",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b1e0b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:44:23.328995Z",
     "start_time": "2023-07-28T13:44:23.315323Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "# ROMY coordinates\n",
    "config['ROMY_lon'] = 11.275501\n",
    "config['ROMY_lat'] = 48.162941\n",
    "\n",
    "# duration of event in seconds\n",
    "config['duration'] = 7200\n",
    "\n",
    "# frequency range for bandpass filter\n",
    "config['fmin'] = 0.01 # in Hz   urspr. 0.01\n",
    "config['fmax'] = 2 # in Hz    urspr. 0.1\n",
    "\n",
    "# path for figures to store\n",
    "config['outpath_figs'] = \"C:/Bachelorarbeit/figures/\"\n",
    "\n",
    "# path for output data\n",
    "config['outpath_data'] = \"C:/Bachelorarbeit/data/waveformsROMYRLAS/\"\n",
    "\n",
    "# specify seed codes of stations that should be used for the analysis\n",
    "config['seeds'] = [#\"BW.ROMY.10.BJZ\",# \"BW.ROMY..BJU\", \"BW.ROMY..BJV\", \"BW.ROMY..BJW\", # ringlaser ROMY\n",
    "                   \"BW.RLAS..BJZ\", # ringlaser G\n",
    "                  #\"GR.FUR..BHZ\", \"GR.FUR..BHN\", \"GR.FUR..BHE\", # seismometer ROMY\n",
    "                  #\"GR.WET..BHZ\", \"GR.WET..BHN\", \"GR.WET..BHE\" # seismometer G\n",
    "                  ]\n",
    "\n",
    "# path to catalogs\n",
    "config['path_to_catalog'] = \"C:/Bachelorarbeit/data/catalogs/\"\n",
    "\n",
    "config['catalog'] = \"ROMY_global_catalog_20190101_20250531.pkl\"\n",
    "\n",
    "# set if existing files should be skipped\n",
    "config['skip_existing'] = True\n",
    "\n",
    "# set if figures should be saved\n",
    "config['save_figures'] = True\n",
    "\n",
    "# set if waveform data should be stored\n",
    "config['store_waveforms'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eed2cb",
   "metadata": {},
   "source": [
    "## Load Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0d935",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:44:23.346586Z",
     "start_time": "2023-07-28T13:44:23.329957Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "events = pd.read_pickle(config['path_to_catalog']+config['catalog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f593187-2f2a-4096-a147-4c6b263c18ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events['origin'] = events.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure only events with magnitude > 6 are considered\n",
    "events = events[events.magnitude > 6]\n",
    "print(\"Event number: \", events.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c94250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid events that are too close to each other in time\n",
    "events['elapsed_time'] = events.timestamp.diff()\n",
    "events = events[events.elapsed_time > pd.Timedelta(minutes=60)]\n",
    "print(\"Event number: \", events.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f799f-8b14-4be8-b9f5-30736e3810b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter catalog events by date\n",
    "#events = events[(events.timestamp > \"2024-05-01\") & (events.timestamp < \"2024-12-24\")]\n",
    "#events = events[\n",
    " #   (events.timestamp > \"2020-01-01\") &\n",
    "  #  (events.timestamp < \"2025-06-03\") \n",
    "   # ]\n",
    "#print(\"Event number: \", events.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a84b7ed",
   "metadata": {},
   "source": [
    "Prepare a status dataframe to mark if data was obtained for specific event and seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ee545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'events' is your existing DataFrame with event information\n",
    "# Create a new DataFrame with event number and origin time\n",
    "event_status = pd.DataFrame({\n",
    "    'event_number': [f\"{i:03d}\" for i in range(events.shape[0])],\n",
    "    'origin_time': events.origin.values\n",
    "})\n",
    "\n",
    "# Set index to event_number for easier reference\n",
    "event_status.set_index('event_number', inplace=True)\n",
    "\n",
    "# Add a column for each seed, initialized to False\n",
    "for seed in config['seeds']:\n",
    "    event_status[seed] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da49565",
   "metadata": {},
   "source": [
    "# RUN LOOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c8158d",
   "metadata": {},
   "source": [
    "Loop over events in catalog and request data for each event. Store data or event plots if\n",
    "- skip existing files\n",
    "- save figures\n",
    "- store waveforms\n",
    "\n",
    "is set in configurations, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c5de6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:52:12.563856Z",
     "start_time": "2023-07-28T13:52:12.263045Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "global errors\n",
    "\n",
    "errors = []\n",
    "adr_status = []\n",
    "i=0\n",
    "# loop over all events\n",
    "for jj in range(events.shape[0]):\n",
    "   \n",
    "      # make event number\n",
    "    num = str(jj).rjust(3, \"0\")\n",
    "    print(f\"\\n -> {num} {events.origin.iloc[jj]} \")\n",
    "\n",
    "    # adjust event name string\n",
    "    try:\n",
    "        event_name = str(events.origin.iloc[jj]).replace(\"-\",\"\").replace(\":\",\"\").replace(\" \", \"_\").split(\".\")[0]\n",
    "    except:\n",
    "        print(f\" -> {num}: error for {events.origin.iloc[jj]}\")\n",
    "        continue\n",
    "\n",
    "    # check if output directory exists\n",
    "    if not os.path.isdir(config['outpath_figs']+\"raw/\"):\n",
    "        print(\"created: \", config['outpath_figs']+\"raw/\")\n",
    "        os.makedirs(config['outpath_figs']+\"raw/\")\n",
    "\n",
    "    # check if file already exists\n",
    "    config['skip_existing'] = False\n",
    "    \n",
    "    if config['skip_existing']:\n",
    "        if i<10:\n",
    "            filename = config['outpath_figs']+\"raw/\"+f\"00{i}_{event_name}_raw.png\"\n",
    "        if i>=10:\n",
    "            filename = config['outpath_figs']+\"raw/\"+f\"0{i}_{event_name}_raw.png\"\n",
    "        i += 1\n",
    "        print(filename)\n",
    "        print(os.path.isfile(filename))\n",
    "        if os.path.isfile(filename):\n",
    "            print(f\" -> file alread exits for {event_name}\")\n",
    "            continue\n",
    "    \n",
    "    #um die entfernung zu berechnen\n",
    "    ev_lat = events.latitude.iloc[jj]\n",
    "    ev_lon = events.longitude.iloc[jj]\n",
    "    sta_lat = config['ROMY_lat']\n",
    "    sta_lon = config['ROMY_lon']\n",
    "    distance_m, az, baz = gps2dist_azimuth(ev_lat, ev_lon, sta_lat, sta_lon)\n",
    "    distance_km = distance_m / 1000\n",
    "    ev_depth = events.depth.iloc[jj] / 1000\n",
    "    origin_time = events.origin.iloc[jj]\n",
    "    magnitude = events.magnitude.iloc[jj]\n",
    "    # configuration adjustments for plots\n",
    "    config['title'] = (f\"M{magnitude:.1f} - {distance_km:.0f} km @ {ev_depth:.0f} km | {origin_time} UTC\")\n",
    "    config['tbeg'] = obs.UTCDateTime(str(events.origin.iloc[jj]))\n",
    "\n",
    "    # same endtime for all\n",
    "    config['tend'] = config['tbeg'] + config['duration']\n",
    "\n",
    "    st0 = obs.Stream()\n",
    "    if os.path.isfile(config['outpath_data']+f\"{num}_{event_name}.mseed\"):\n",
    "        st0 = read(config['outpath_data']+f\"{num}_{event_name}.mseed\")\n",
    "        data_vorhanden = True\n",
    "        print(data_vorhanden)\n",
    "    else:\n",
    "        data_vorhanden = False\n",
    "        st0 = obs.Stream()\n",
    "        print(data_vorhanden)\n",
    "        for seed in config['seeds']:\n",
    "    \n",
    "            try:\n",
    "                # request data for FUR\n",
    "                if \"FUR\" in seed:\n",
    "                    stx, invx = __querrySeismoData( seed_id=seed,\n",
    "                                                    starttime=config['tbeg'],\n",
    "                                                    endtime=config['tend'],\n",
    "                                                    repository='online',\n",
    "                                                    path=None,\n",
    "                                                    restitute=True,\n",
    "                                                    detail=None,\n",
    "                                                    fill_value=None,\n",
    "                                                )\n",
    "                    if len(stx) == 0:\n",
    "                        print(f\" -> data missing for {seed}\")\n",
    "                    else:\n",
    "                        event_status.loc[num, seed] = True\n",
    "                    st0 += stx\n",
    "                \n",
    "                # request data for WET\n",
    "                elif \"WET\" in seed:\n",
    "                    stx, invx = __querrySeismoData( seed_id=seed,\n",
    "                                                    starttime=config['tbeg'],\n",
    "                                                    endtime=config['tend'],\n",
    "                                                    repository='online',\n",
    "                                                    path=None,\n",
    "                                                    restitute=True,\n",
    "                                                    detail=None,\n",
    "                                                    fill_value=None,\n",
    "                                                )\n",
    "                    if len(stx) == 0:\n",
    "                        print(f\" -> data missing for {seed}\")\n",
    "                    else:\n",
    "                        event_status.loc[num, seed] = True\n",
    "                    st0 += stx\n",
    "                \n",
    "                # request ADR data from archive\n",
    "                \n",
    "                elif \"ROMY.22\" in seed:\n",
    "                    stx, invx = __querrySeismoData( seed_id=seed,\n",
    "                                                    starttime=config['tbeg'],\n",
    "                                                    endtime=config['tend'],\n",
    "                                                    repository='archive',\n",
    "                                                    path=config['path_to_archive']+\"temp_archive/\",\n",
    "                                                    restitute=True,\n",
    "                                                    detail=None,\n",
    "                                                    fill_value=None,\n",
    "                                                )\n",
    "    \n",
    "                    if len(stx) == 0:\n",
    "                        print(f\" -> data missing for {seed}\")\n",
    "                    else:\n",
    "                        event_status.loc[num, seed] = True\n",
    "                    st0 += stx\n",
    "                \n",
    "                # request ringlaser data from george\n",
    "               # elif \"ROMY\" in seed:\n",
    "                #    print(\"ROMY\")\n",
    "                 #   stx, invx = __querrySeismoData( seed_id=seed,\n",
    "                  #                                  starttime=config['tbeg'],\n",
    "                   #                                 endtime=config['tend'],\n",
    "                    #                                repository='george',\n",
    "                     #                               path=None,\n",
    "                      #                              restitute=True,\n",
    "                       #                         detail=None,\n",
    "                        #                        fill_value=None,\n",
    "                         #                   )\n",
    "                  #  if len(stx) == 0:\n",
    "                   #     print(f\" -> data missing for {seed}\")\n",
    "                    #else:\n",
    "                     #   event_status.loc[num, seed] = True\n",
    "                    #st0 += stx\n",
    "                elif \"ROMY\" in seed:\n",
    "                    print(\"ROMY\")\n",
    "                    try:\n",
    "                        stx, invx = __querrySeismoData(\n",
    "                            seed_id=seed,\n",
    "                            starttime=config['tbeg'],\n",
    "                            endtime=config['tend'],\n",
    "                            repository='george',\n",
    "                            path=None,\n",
    "                            restitute=True,\n",
    "                            detail=None,\n",
    "                            fill_value=None,\n",
    "                        )\n",
    "                        \n",
    "                        if len(stx) == 0:\n",
    "                            print(f\" -> data missing for {seed}\")\n",
    "                        else:\n",
    "                            event_status.loc[num, seed] = True\n",
    "                            st0 += stx\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\" -> error retrieving data for {seed}: {e}\")\n",
    "\n",
    "                elif \"RLAS\" in seed:\n",
    "                    print(\"RLAS\")\n",
    "                    stx, invx = __querrySeismoData( seed_id=seed,\n",
    "                                                    starttime=config['tbeg'],\n",
    "                                                    endtime=config['tend'],\n",
    "                                                    repository='george',\n",
    "                                                    path=None,\n",
    "                                                    restitute=True, \n",
    "                                                    detail=None,\n",
    "                                                    fill_value=None,\n",
    "                                                )\n",
    "                    if len(stx) == 0:\n",
    "                        print(f\" -> data missing for {seed}\")\n",
    "                    else:\n",
    "                        event_status.loc[num, seed] = True\n",
    "                    st0 += stx\n",
    "    \n",
    "                else:\n",
    "                    print(f\" -> {seed} not found\")\n",
    "                                                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(f\" -> failed to request {seed} for event: {events.origin.iloc[jj]}\")\n",
    "                errors.append(f\" -> failed to request {seed} for event: {events.origin.iloc[jj]}\")\n",
    "                continue\n",
    "\n",
    "    # stort stream by channel\n",
    "    st0 = st0.sort()\n",
    "\n",
    "    # check if any data is masked\n",
    "    for tr in st0:\n",
    "        if isinstance(tr.data, np.ma.MaskedArray):\n",
    "            print(f\" -> {tr.stats.channel} has masked data. Filled with zeros.\")\n",
    "            tr.data = tr.data.filled(fill_value=0)\n",
    "\n",
    "    # processing data stream\n",
    "    print(\" -> processing data stream ...\")\n",
    "    st1 = st0.copy();\n",
    "    st1 = st1.detrend(\"linear\");\n",
    "    st1 = st1.taper(0.1);\n",
    "    st1 = st1.filter(\"bandpass\", freqmin=config['fmin'], freqmax=config['fmax'], corners=4, zerophase=True);\n",
    "\n",
    "    # trim data stream\n",
    "    st1 = st1.trim(config['tbeg'], config['tend']);\n",
    "    st0 = st0.trim(config['tbeg'], config['tend']);\n",
    "    if len(st0) < 2:\n",
    "        print(\"st0<5\")\n",
    "        continue\n",
    "    st1.plot(equal_scale=False);\n",
    "\n",
    "    # store waveform data\n",
    "    if config['store_waveforms']:\n",
    "\n",
    "        # define filename\n",
    "        waveform_filename = f\"{num}_{str(events.origin.iloc[jj]).split('.')[0].replace('-','').replace(':','').replace(' ','_')}.mseed\"\n",
    "\n",
    "        # check if subdirectory exists\n",
    "        if not os.path.isdir(config['outpath_data']):\n",
    "            print(\"created: \", config['outpath_data'])\n",
    "            os.makedirs(config['outpath_data'])\n",
    "\n",
    "        # store waveform data\n",
    "        try:\n",
    "            st0.write(config['outpath_data']+waveform_filename);\n",
    "            print(f\" -> stored at: {config['outpath_data']+waveform_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\" -> error storing waveform: {e}\")\n",
    "            errors.append(f\" -> error storing waveform: {e}\")\n",
    "\n",
    "    # saving figures\n",
    "    if config['save_figures']:\n",
    "\n",
    "        # check if subdirectory exists\n",
    "        if not os.path.isdir(config['outpath_figs']+\"raw/\"):\n",
    "            print(\"created: \", config['outpath_figs']+\"raw/\")\n",
    "            os.makedirs(config['outpath_figs']+\"raw/\")\n",
    "\n",
    "        # plotting figure\n",
    "        fig1 = st0.plot(equal_scale=False, show=False)#;  eig code\n",
    "        #fig1 = __makeplot(config, st0)\n",
    "        # store figure\n",
    "        fig1.savefig(config['outpath_figs']+\"raw/\"+f\"{num}_{event_name}_raw.png\", \n",
    "                     dpi=150, bbox_inches='tight', pad_inches=0.05)\n",
    "        \n",
    "        # check if subdirectory exists  \n",
    "        if not os.path.isdir(config['outpath_figs']+\"filteredROMYRLAS/\"):\n",
    "            print(\"created: \", config['outpath_figs']+\"filteredROMYRLAS/\")\n",
    "            os.makedirs(config['outpath_figs']+\"filteredROMYRLAS/\")\n",
    "\n",
    "        fig2 = st1.plot(equal_scale=False, show=False);\n",
    "\n",
    "        fig2.savefig(config['outpath_figs']+\"filteredROMYRLAS/\"+f\"{num}_{event_name}_filtered.png\", \n",
    "                        dpi=150, bbox_inches='tight', pad_inches=0.05)      \n",
    "        print(\"Saved\")\n",
    "        del fig1, fig2\n",
    "        gc.collect()\n",
    "\n",
    "pprint(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afecb2f1",
   "metadata": {},
   "source": [
    "Plot status of data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31afb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_status_plot(event_status, title=\"Event Data Retrieval Status\"):\n",
    "    # Make a copy and prepare data\n",
    "    df = event_status.copy()\n",
    "    \n",
    "    if 'origin_time' in df.columns:\n",
    "        # Create labels with event number and origin time\n",
    "        y_labels = [f\"{idx} ({str(time).split('.')[0]})\" \n",
    "                   for idx, time in zip(df.index, df['origin_time'])]\n",
    "        df = df.drop(columns=['origin_time'])\n",
    "    else:\n",
    "        y_labels = df.index.tolist()\n",
    "    \n",
    "    # Create the heatmap\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=df.values.astype(int),\n",
    "        x=df.columns,\n",
    "        y=y_labels,\n",
    "        colorscale=[[0, 'rgb(255,80,80)'], [1, 'rgb(80,220,80)']],\n",
    "        showscale=False,\n",
    "        text=[[(\"✓\" if val else \"✗\") for val in row] for row in df.values],\n",
    "        texttemplate=\"%{text}\",\n",
    "        textfont={\"color\":\"white\"}\n",
    "    ))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        # xaxis_title=\"Seed IDs\",\n",
    "        # yaxis_title=\"Event Number (Origin Time)\",\n",
    "        xaxis={'side': 'top'},\n",
    "        height=max(500, len(df) * 25),  # Dynamic height\n",
    "        width=max(800, len(df.columns) * 60),  # Dynamic width\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "fig = create_interactive_status_plot(event_status)\n",
    "fig.write_html(config['outpath_figs'] + \"event_status_interactive.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c739a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
